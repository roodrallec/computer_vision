%% *UNIVERSITAT DE BARCELONA*
%% *COMPUTER VISION *
%% *LAB 11 REPORT*
% *JORGE ALEXANDER & EMER RODRIGUEZ FORMISANO*
% 
% VLFeat configuration:
%%
clear all;
VLFEAT_DIR = 'VLFEATROOT';
run(fullfile(VLFEAT_DIR,'/toolbox/vl_setup'));
vl_version;
%% 
% a) 
% 
% First, train the model with a subset of categories:
%%
categorySubset = { 'Leopards', 'accordion', 'pizza', 'Faces' };
modified_phow_caltech101(categorySubset);
modelPath = fullfile('data','baseline-model.mat');
load(modelPath);
%% 
% Add a function to train visualize the images in a green framework if the 
% classification is correct and in a red framework if it does not:
%%
% 
% Choose imageCount random images to classify and draw border around
% 
imageCount = 9;
imageBaseDir = fullfile('data','caltech-101','101_ObjectCategories');
imagePaths = buildImagePaths(imageBaseDir, categorySubset);
visualizeImgClass(imagePaths, model);
%% 
% b) 
% 
% _What are the PHOW descriptors?  _
% 
% They represent the Pyramid Histogram Of visual Words. 
% 
% The function to obtain them is 
%%
%[FRAMES, DESCRS] = vl_phow(IMG)
%% 
% DESCRS, Each column of DESCRS is the descriptor of the corresponding frame 
% in FRAMES. A descriptor is a 128-dimensional vector of class UINT8.
% 
% It represents a 4x4 spatial histogram of gradient orientations, each with 
% 8 different directions, leading to a 4x4x8=128 dimensional vector.
% 
% FRAMES(1:2,:) are the x,y coordinates of the center of each descriptor, 
% FRAMES(3,:) is the contrast of the descriptor, as returned by VL_DSIFT() (for 
% colour variant, contranst is computed on the intensity channel). FRAMES(4,:) 
% is the size of the bin of the descriptor.
% 
% _What does the Sizes parameter mean? _
% 
% It's the scales at which the dense SIFT features are extracted. Each value 
% is used as the spatial bin size in pixels when extracting a dense set of SIFT 
% features from the image.
% 
% _What does happen if the Sizes parameter is augmented? _
% 
% From the lectures, the code to calculate the phow descriptors:

% step = 5;
% for size=[5,7,10,12]
%     [x,y]=meshgrid(1:step:width, 1:step:height);
%     frames = [x(:)'; y(:)'];
%     frames(3,:) = size/3;
%     frames(4,:) = 0;
%     [frames, descrs] = vl_sift(im, 'Frames', frames);
% end
%% 
% It can be observed that if the size is increased the size of the bin of 
% the descriptor is increased.				
% 
% _What does the Step parameter mean?_ 
% 
% Step (in pixels) of the grid at which the dense SIFT features are extracted.
% 
% _What does happen if the Step parameter is augmented?_
% 
% If the step parameter is augmented, then a grid with a lower resolution 
% is created, and less features are extracted.
% 
% c) 
% 
% _What are the words in the algorithm?_ 
% 
% _How are they extracted?_ 
% 
% _What is their dimension?_ 
% 
% _How their number does affect the accuracy of the results? _
%%
vocabPath = fullfile('data','baseline-vocab.mat');
load(vocabPath);
vocabOriginal = vocab;
%% 
% We observe that the vocab consists of 128x600. The 128 represents the 
% 128 dimensions of the sift descriptors generated by _vl_phow_, as explained 
% before. The 600 columns represent one word each. To extract the vocab, k-means 
% is applied to the sift descriptors. Each word of the vocab represents the centre 
% of the k-means clusters found. From the phow function code:

% vocab = vl_kmeans(descrs, conf.numWords, 'verbose', 'algorithm', 'elkan', 'MaxNumIterations', 50) ;
imagePaths = buildImagePaths(imageBaseDir, {'Faces'});
visualizeImgClass(imagePaths, model);
%% 
% Now we reduce the number of words and see what happens.
%%
words = 2;
vocab = vocab(:,1:words);
save(vocabPath, 'vocab');
visualizeImgClass(imagePaths, model);
%% 
% The number of words does not seem to have affected the classification 
% of faces.

% Restore original vocab
vocab = vocabOriginal;
save(vocabPath, 'vocab');
% __